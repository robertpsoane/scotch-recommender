{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "moved-korean",
   "metadata": {},
   "source": [
    "# Preprocessing Scotch Notes\n",
    "\n",
    "This notebook was used for initial preprocessing of scotch data.\n",
    "\n",
    "Initial functions and classes were designed - moved to whiskynlp scripts later on.\n",
    "\n",
    "Initially considering number of occurences, when re-writing graph functions paid more attention to KW extraction methods and chose to go for an eigencentrality based method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "black-acoustic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from hashlib import md5\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phantom-volunteer",
   "metadata": {},
   "source": [
    "## Adding IDs and removing duplicates"
   ]
  },
  {
   "cell_type": "raw",
   "id": "private-safety",
   "metadata": {},
   "source": [
    "df = pd.read_csv(\"scotch.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "driving-installation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an ID for each whisky\n",
    "def hashEl(name, url):\n",
    "    \"\"\"\n",
    "    MD5 hash of Name and URL\n",
    "    Hash each individually, use max/min functions to ensure hash 2 happens in same order irrespective of which get's input first.\n",
    "    \"\"\"\n",
    "    h1 = md5(name.encode()).hexdigest()\n",
    "    h2 = md5(url.encode()).hexdigest()\n",
    "    h3 = max(h1, h2) + min(h1, h2)\n",
    "    h4 = md5(h3.encode()).hexdigest()\n",
    "    return h3"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aging-equality",
   "metadata": {},
   "source": [
    "# Creating ID, dropping duplicates\n",
    "df[\"ID\"] = df.apply((lambda x: hashEl(x.Name, x.URL)), axis=1)\n",
    "df = df.drop_duplicates(subset=\"ID\", keep=\"last\")\n",
    "df= df.reset_index()\n",
    "cols = [\"ID\", \"Type\", \"Name\", \"Description\", \"Nose\", \"Palate\", \"Finish\", \"Price\", \"Size\", \"Abv\",\"URL\"]\n",
    "df = df[cols]\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "polyphonic-documentary",
   "metadata": {},
   "source": [
    "df.to_csv(\"scotch-no-dupes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "exotic-pharmacology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Type</th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Nose</th>\n",
       "      <th>Palate</th>\n",
       "      <th>Finish</th>\n",
       "      <th>Price</th>\n",
       "      <th>Size</th>\n",
       "      <th>Abv</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>495334d7384f4c9a933a156cb57639770cd9c8bca00ac7...</td>\n",
       "      <td>blended malt scotch</td>\n",
       "      <td>Monkey Shoulder Blended Malt Scotch Whisky</td>\n",
       "      <td>Monkey Shoulder Scotch is a superb blended mal...</td>\n",
       "      <td>An elegant, stylish nose of marmalade, Crema C...</td>\n",
       "      <td>Very malty, creamy delivery with a suggestion ...</td>\n",
       "      <td>Medium length, spicy oak and a hint of pepperm...</td>\n",
       "      <td>25.94</td>\n",
       "      <td>70.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>https://www.masterofmalt.com/whiskies/monkey-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e193fa8dee0bb9422054efd5dfb7f2c2628815243b584b...</td>\n",
       "      <td>blended malt scotch</td>\n",
       "      <td>Johnnie Walker Green Label 15 Year Old</td>\n",
       "      <td>One of those harder-to-find whiskies, Johnnie ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.95</td>\n",
       "      <td>70.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>https://www.masterofmalt.com/whiskies/johnnie-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d3ba34da7b98276f2da2ab313ff9e6cdc5d476d253a05e...</td>\n",
       "      <td>blended malt scotch</td>\n",
       "      <td>The Naked Grouse</td>\n",
       "      <td>An interesting addition to the Famous Grouse r...</td>\n",
       "      <td>Smooth and oily with notes of cherry compote, ...</td>\n",
       "      <td>Sherried and thick with notes of sultanas, sti...</td>\n",
       "      <td>Medium, with notes of cocoa, oak and just a so...</td>\n",
       "      <td>26.49</td>\n",
       "      <td>70.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>https://www.masterofmalt.com/whiskies/naked-gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b74f75c04d65218b3b094130583f53b58b58d331f47d44...</td>\n",
       "      <td>blended malt scotch</td>\n",
       "      <td>Scallywag</td>\n",
       "      <td>Big Peat's gone and got himself a trusty sidek...</td>\n",
       "      <td>Sweetness jumps up like an excited puppy. Icin...</td>\n",
       "      <td>The sweetness surprisingly retreats, revealing...</td>\n",
       "      <td>A pinch of oak spice joins the vanilla and she...</td>\n",
       "      <td>38.75</td>\n",
       "      <td>70.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>https://www.masterofmalt.com/whiskies/douglas-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a6f33f754e0dbb178b5fef3ff0d031f470918b9477703c...</td>\n",
       "      <td>blended malt scotch</td>\n",
       "      <td>Monkey Shoulder Smokey Monkey</td>\n",
       "      <td>A peaty variant of the excellent Monkey Should...</td>\n",
       "      <td>Honeydew melon, flamed orange peel, a touch of...</td>\n",
       "      <td>Vanilla sits at the core, its earthy notes bol...</td>\n",
       "      <td>Toffee Crisp bars and the last wafts of drying...</td>\n",
       "      <td>27.44</td>\n",
       "      <td>70.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>https://www.masterofmalt.com/whiskies/monkey-s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  ID                 Type  \\\n",
       "0  495334d7384f4c9a933a156cb57639770cd9c8bca00ac7...  blended malt scotch   \n",
       "1  e193fa8dee0bb9422054efd5dfb7f2c2628815243b584b...  blended malt scotch   \n",
       "2  d3ba34da7b98276f2da2ab313ff9e6cdc5d476d253a05e...  blended malt scotch   \n",
       "3  b74f75c04d65218b3b094130583f53b58b58d331f47d44...  blended malt scotch   \n",
       "4  a6f33f754e0dbb178b5fef3ff0d031f470918b9477703c...  blended malt scotch   \n",
       "\n",
       "                                         Name  \\\n",
       "0  Monkey Shoulder Blended Malt Scotch Whisky   \n",
       "1      Johnnie Walker Green Label 15 Year Old   \n",
       "2                            The Naked Grouse   \n",
       "3                                   Scallywag   \n",
       "4               Monkey Shoulder Smokey Monkey   \n",
       "\n",
       "                                         Description  \\\n",
       "0  Monkey Shoulder Scotch is a superb blended mal...   \n",
       "1  One of those harder-to-find whiskies, Johnnie ...   \n",
       "2  An interesting addition to the Famous Grouse r...   \n",
       "3  Big Peat's gone and got himself a trusty sidek...   \n",
       "4  A peaty variant of the excellent Monkey Should...   \n",
       "\n",
       "                                                Nose  \\\n",
       "0  An elegant, stylish nose of marmalade, Crema C...   \n",
       "1                                                NaN   \n",
       "2  Smooth and oily with notes of cherry compote, ...   \n",
       "3  Sweetness jumps up like an excited puppy. Icin...   \n",
       "4  Honeydew melon, flamed orange peel, a touch of...   \n",
       "\n",
       "                                              Palate  \\\n",
       "0  Very malty, creamy delivery with a suggestion ...   \n",
       "1                                                NaN   \n",
       "2  Sherried and thick with notes of sultanas, sti...   \n",
       "3  The sweetness surprisingly retreats, revealing...   \n",
       "4  Vanilla sits at the core, its earthy notes bol...   \n",
       "\n",
       "                                              Finish  Price  Size   Abv  \\\n",
       "0  Medium length, spicy oak and a hint of pepperm...  25.94  70.0  40.0   \n",
       "1                                                NaN  38.95  70.0  43.0   \n",
       "2  Medium, with notes of cocoa, oak and just a so...  26.49  70.0  40.0   \n",
       "3  A pinch of oak spice joins the vanilla and she...  38.75  70.0  46.0   \n",
       "4  Toffee Crisp bars and the last wafts of drying...  27.44  70.0  40.0   \n",
       "\n",
       "                                                 URL  \n",
       "0  https://www.masterofmalt.com/whiskies/monkey-s...  \n",
       "1  https://www.masterofmalt.com/whiskies/johnnie-...  \n",
       "2  https://www.masterofmalt.com/whiskies/naked-gr...  \n",
       "3  https://www.masterofmalt.com/whiskies/douglas-...  \n",
       "4  https://www.masterofmalt.com/whiskies/monkey-s...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"scotch-no-dupes.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facial-federation",
   "metadata": {},
   "source": [
    "## Extracting to graph\n",
    "An issue with whisky tasting notes, is each document usually doesn't consist of one word more than once.  Means traditional processing techniques don't necessarily extract the right keywords.\n",
    "We create a network graph of keywords, where each word is a node, with edges being co-occurences in individual tasting notes, with each edge weighted by number of co-occurences.\n",
    "\n",
    "Another issue, is that words have different meanings, such as `peat`.  In normal english, peat is a fuel, and a synonym might be grass, in whisky peat and grass are about as far from each other as can be possible.\n",
    "\n",
    "A wordnet lemmatizer fails to lemmatize many words - need to build own lemmatizer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infinite-toilet",
   "metadata": {},
   "source": [
    "### Functions for making corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "manufactured-reasoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Corpus Function\n",
    "\n",
    "# Removing Punctuation\n",
    "import string\n",
    "punct = string.punctuation+'’'\n",
    "\n",
    "def makeCorpus(lst):\n",
    "    out = ''\n",
    "    for el in lst:\n",
    "        out = out + el + '  '\n",
    "    return out\n",
    "\n",
    "def makeList(df, col):\n",
    "    \"\"\"\n",
    "    Extracts \n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for row in range(len(df.index)-1):\n",
    "        # Extracting cell\n",
    "        row_str = df[col][row].lower()\n",
    "        # Removing punctuation\n",
    "        row_str = row_str.translate(str.maketrans(' ',' ',punct))\n",
    "        out.append(row_str)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-rotation",
   "metadata": {},
   "source": [
    "### Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "executed-burning",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag\n",
    "\n",
    "# Extracting stop words\n",
    "from nltk.corpus import stopwords\n",
    "whisky_stopwords = [\"nose\", \"palate\", \"finish\", \"doesnt\", \"eye\", \"touch\", \"note\", \"hint\", \"good\",\"linger\",\"lingers\",\"alongside\",\"mar\"]\n",
    "swords = set(stopwords.words(\"english\") + whisky_stopwords)\n",
    "\n",
    "\n",
    "class WhiskyLemmatizer(WordNetLemmatizer):\n",
    "    '''\n",
    "    An extension on the WordNet Lemmatizer with added context for whisky\n",
    "    '''\n",
    "        \n",
    "    def __init__(self):\n",
    "        self.whisky_words = {\n",
    "            \"peated\": \"peat\",\n",
    "            \"peaty\": \"peat\",\n",
    "            \"smokey\": \"smoke\",\n",
    "            \"smoky\": \"smoke\",\n",
    "            \"sherried\": \"sherry\"\n",
    "    }\n",
    "    \n",
    "    def lemmatize(self, word):\n",
    "        # Caches lemmatized words to avoid lookups\n",
    "        if word in self.whisky_words:\n",
    "            out = self.whisky_words[word]\n",
    "        else:\n",
    "            tag = self.tag(word)\n",
    "            out = super().lemmatize(word, pos=tag)\n",
    "            self.whisky_words[word] = out\n",
    "        return out\n",
    "    \n",
    "    def lemmatizeList(self, lst):\n",
    "        return [self.lemmatize(w) for w in lst]\n",
    "    \n",
    "    def whiskySub(self, word):\n",
    "        if word in self.whisky_words:\n",
    "            return self.whisky_words[word]\n",
    "        else:\n",
    "            return word\n",
    "    \n",
    "    def tag(self, word):\n",
    "        tag = pos_tag([word])\n",
    "        tag = pos_tag([word])[0][1][0].lower()\n",
    "        if tag == \"v\":\n",
    "            return \"v\"\n",
    "        if tag == \"j\":\n",
    "            return \"a\"\n",
    "        else:\n",
    "            return \"n\"\n",
    "        \n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"<WhiskyLemmatizer>\"\n",
    "    \n",
    "lemmatizer = WhiskyLemmatizer()\n",
    "\n",
    "\n",
    "def tokenFilter(corpus):\n",
    "    tokens = lemmatizer.lemmatizeList(word_tokenize(corpus))\n",
    "    filtered = [w for w in tokens if (not w in swords)]\n",
    "    return filtered\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspended-gross",
   "metadata": {},
   "source": [
    "### Graph making functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "romantic-specialist",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeNodes(corpus):\n",
    "    filtered = tokenFilter(corpus)\n",
    "    nodes_dict = {}\n",
    "    for word in filtered:\n",
    "        if word in nodes_dict:\n",
    "            nodes_dict[word] += 1\n",
    "        else:\n",
    "            nodes_dict[word] = 1\n",
    "    \n",
    "    node_names = list(nodes_dict.keys())\n",
    "    nodes = []\n",
    "    for name in node_names:\n",
    "        nodes.append({\n",
    "            \"name\":name,\n",
    "            \"n_occ\":int(nodes_dict[name])\n",
    "        })\n",
    "    return nodes, node_names\n",
    "        \n",
    "\n",
    "def incrementEdge(edges, from_idx, to_idx):\n",
    "    from_s, to_s = str(from_idx), str(to_idx)\n",
    "    if from_s in edges:\n",
    "        if to_s in edges[from_s]:\n",
    "            edges[from_s][to_s] += 1\n",
    "        else:\n",
    "            edges[from_s][to_s] = 1\n",
    "    else:\n",
    "        edges[from_s] = {to_s : 1}\n",
    "    return\n",
    "\n",
    "\n",
    "def makeNoteEdges(note, nodes, edges):\n",
    "    descs = tokenFilter(note)\n",
    "    descs = [d for d in descs if d in nodes]\n",
    "    node_idxs = [nodes.index(w) for w in descs if w in nodes]\n",
    "    n_descs = len(descs)\n",
    "    for note_idx1 in range(n_descs - 1):\n",
    "        for note_idx2 in range(note_idx1+1, n_descs):\n",
    "            if note_idx1 != note_idx2:\n",
    "                node1 = node_idxs[note_idx1]\n",
    "                node2 = node_idxs[note_idx2]\n",
    "                from_idx = min(node1, node2)\n",
    "                to_idx = max(node1, node2)\n",
    "                incrementEdge(edges, from_idx, to_idx)\n",
    "    return\n",
    "\n",
    "        \n",
    "def initialMakeEdges(lst, nodes):\n",
    "    edges = {}\n",
    "    for note in lst:\n",
    "        makeNoteEdges(note, nodes, edges)\n",
    "    return edges\n",
    "\n",
    "def makeEdges(lst, names, verbose=False):\n",
    "    init_edges = initialMakeEdges(lst, names)\n",
    "    edges = []\n",
    "    for start in init_edges.keys():\n",
    "        for end in init_edges[start].keys():\n",
    "            start_int, end_int = int(start), int(end)\n",
    "            edge = {\n",
    "                \"from\": start_int,\n",
    "                \"to\": end_int,\n",
    "                \"weight\": init_edges[start][end],\n",
    "            }\n",
    "            if verbose:\n",
    "                # Add english description to edge.\n",
    "                desc = {\n",
    "                    \"from\": names[start_int],\n",
    "                    \"to\": names[end_int]\n",
    "                }\n",
    "                edge[\"english\"] = desc\n",
    "            edges.append(edge)\n",
    "    return edges\n",
    "    \n",
    "\n",
    "def makeGraph(corpus_list, verbose_edges=False, ):\n",
    "    corpus = makeCorpus(corpus_list)\n",
    "    \n",
    "    nodes, names = makeNodes(corpus)\n",
    "    edges = makeEdges(corpus_list, names, verbose_edges)\n",
    "    \n",
    "    graph = {\n",
    "        \"nodes\": nodes,\n",
    "        \"edges\": edges,\n",
    "        \"node-names\": names\n",
    "    }\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-lesson",
   "metadata": {},
   "source": [
    "### Graph Analysis functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "super-sunglasses",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortNodesByNOcc(graph):\n",
    "    \"\"\"\n",
    "    Sorts nodes by n occ : requires each node to know its n occ.  \n",
    "    This should be the case as its n occ is included when making graph\n",
    "    \"\"\"\n",
    "    # Extracting nodes to data frame\n",
    "    nodes = pd.DataFrame(graph[\"nodes\"])\n",
    "    \n",
    "    # Renaming columns and sorting graph\n",
    "    nodes.columns = [\"Descriptor\", \"N Occ\"]\n",
    "    nodes = nodes.sort_values(\"N Occ\",ascending=False)\n",
    "    nodes = nodes.reset_index()\n",
    "    return nodes[[\"Descriptor\", \"N Occ\"]]\n",
    "\n",
    "def getUnrepresentedCount(corpus_list, nodes):\n",
    "    \"\"\"\n",
    "    Function to find all descriptors which aren't on graph\n",
    "    \"\"\"\n",
    "    descriptors = list(nodes[\"Descriptor\"])\n",
    "    \n",
    "    n_unrepresented = 0\n",
    "    \n",
    "    for t_note in corpus_list:\n",
    "        desc = tokenFilter(t_note)\n",
    "        matches = [w in descriptors for w in desc]\n",
    "        if True not in matches:\n",
    "            n_unrepresented += 1\n",
    "    \n",
    "    return n_unrepresented"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hispanic-immunology",
   "metadata": {},
   "source": [
    "### Functions to add words to lemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "molecular-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addToLemmatizer(nodes, depth):\n",
    "    \"\"\"\n",
    "    Adds a rough stemming of each of the first `depth` nodes to the lemmatizer.\n",
    "    \"\"\"\n",
    "    # getting unlemmatized common words\n",
    "    list_descriptors = list(nodes[\"Descriptor\"])\n",
    "    describers_d = list_descriptors[:depth]\n",
    "    idx1 = 0\n",
    "    while idx1 < len(describers_d):\n",
    "        idx2 = idx1 + 1\n",
    "        word1 = describers_d[idx1]\n",
    "        while idx2 < len(describers_d):\n",
    "            word2 = describers_d[idx2]\n",
    "            if word2[:len(word1)] == word1:\n",
    "                describers_d.pop(idx2)\n",
    "                break\n",
    "            idx2 += 1\n",
    "        idx1 += 1\n",
    "\n",
    "\n",
    "    for word in describers_d:\n",
    "        unlemma = [w for w in list_descriptors if w[:len(word)]==word]\n",
    "        for unlemma_word in unlemma:\n",
    "            lemmatizer.whisky_words[unlemma_word] = word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-nicholas",
   "metadata": {},
   "source": [
    "## Tasting Note Analysis\n",
    "We follow the following process to analyse the tasting notes:\n",
    "\n",
    "- Make preliminary graph based on hardcoded lemmatizer\n",
    "\n",
    "- Based on N Occ, take each term and add a rough stem to the lemmatizer\n",
    "\n",
    "- Remake the graph with improved lemmatizer\n",
    "\n",
    "### Tasting Note Analysis : Nose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "basic-midwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extracting list of tasting notes from word\n",
    "nose_list = makeList(df.dropna().reset_index(), \"Nose\")\n",
    "\n",
    "# Making a preliminary graph and extracting words\n",
    "nose_graph_prelim = makeGraph(nose_list, verbose_edges=True)\n",
    "nose_occ = sortNodesByNOcc(nose_graph_prelim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "confident-console",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–\n",
      "au\n",
      "de\n",
      "le\n",
      "go\n",
      "px\n",
      "u\n",
      "se\n",
      "9\n",
      "‘\n",
      "18\n",
      "ol\n",
      "10\n",
      "ba\n",
      "oh\n",
      "ii\n",
      "15\n",
      "n\n",
      "12\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "## Noticed that when using len_deg we got some intersting \n",
    "## results - instead looking at short words, all seem \n",
    "## weird - adding to stopwords\n",
    "for word in list(nose_occ[\"Descriptor\"]):\n",
    "    if len(word) < 3:\n",
    "        print(word)\n",
    "        \n",
    "for word in list(nose_occ[\"Descriptor\"]):\n",
    "    if len(word) < 3:\n",
    "        swords.add(word)\n",
    "        \n",
    "# Improving lemmatizer based on 500 stemmed common words\n",
    "addToLemmatizer(nose_occ, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "purple-crisis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remaking nose graph\n",
    "nose_graph = makeGraph(nose_list, verbose_edges=True)\n",
    "nose_n_occ = sortNodesByNOcc(nose_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-packaging",
   "metadata": {},
   "source": [
    "Now that we have a list of lemmatized nose descriptors (minus stopwords), we can apply the same processs to palate and finish\n",
    "### Tasting Note Analysis : Palate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "beginning-attachment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting list of tasting notes from word\n",
    "palate_list = makeList(df.dropna().reset_index(), \"Palate\")\n",
    "\n",
    "# Making a preliminary graph and extracting words\n",
    "palate_graph_prelim = makeGraph(palate_list, verbose_edges=True)\n",
    "palate_occ = sortNodesByNOcc(palate_graph_prelim)\n",
    "\n",
    "# Improving lemmatizer based on 500 stemmed common words\n",
    "addToLemmatizer(palate_occ, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "lyric-expense",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mr\n",
      "8\n",
      "90\n",
      "42\n",
      "ra\n",
      "el\n",
      "“\n",
      "”\n"
     ]
    }
   ],
   "source": [
    "for word in list(palate_occ[\"Descriptor\"]):\n",
    "    if len(word) < 3:\n",
    "        print(word)\n",
    "for word in list(palate_occ[\"Descriptor\"]):\n",
    "    if len(word) < 3:\n",
    "        swords.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "polyphonic-burner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remaking palate graph\n",
    "palate_graph = makeGraph(palate_list, verbose_edges=True)\n",
    "palate_n_occ = sortNodesByNOcc(palate_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-treasury",
   "metadata": {},
   "source": [
    "### Tasting Note Analysis : Finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "charitable-workstation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting list of tasting notes from word\n",
    "finish_list = makeList(df.dropna().reset_index(), \"Finish\")\n",
    "\n",
    "# Making a preliminary graph and extracting words\n",
    "finish_graph_prelim = makeGraph(finish_list, verbose_edges=True)\n",
    "finish_occ = sortNodesByNOcc(finish_graph_prelim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "prompt-designation",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Noticed that when using len_deg we got some intersting \n",
    "## results - instead looking at short words, all seem \n",
    "## weird - adding to stopwords\n",
    "for word in list(finish_occ[\"Descriptor\"]):\n",
    "    if len(word) < 3:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "celtic-weight",
   "metadata": {},
   "outputs": [],
   "source": [
    "addToLemmatizer(finish_occ, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "guided-percentage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remaking finish graph\n",
    "finish_graph = makeGraph(finish_list, verbose_edges=True)\n",
    "finish_n_occ = sortNodesByNOcc(finish_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-biodiversity",
   "metadata": {},
   "source": [
    "### Saving lemmatizer dictionary to json\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "handmade-mission",
   "metadata": {},
   "source": [
    "import json\n",
    "ldict = lemmatizer.whisky_words\n",
    "ldict[\"pepper\"] = \"pepper\"\n",
    "ldict[\"peppermint\"] = \"peppermint\"\n",
    "lemmatizer.whisky_words = ldict\n",
    "ldict\n",
    "with open(\"whiskynlp/whisky_lemmatizer_dict.json\", \"w\") as out:\n",
    "    json.dump(ldict, out)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "concerned-darkness",
   "metadata": {},
   "source": [
    "swords_l = list(swords)\n",
    "swords_j = {\"swords\":swords_l}\n",
    "with open(\"whiskynlp/stopwords.json\", \"w\") as out:\n",
    "    json.dump(swords_j, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungarian-configuration",
   "metadata": {},
   "source": [
    "### Tasting Note Analysis : Remaking graphs with updated lemmatizer"
   ]
  },
  {
   "cell_type": "raw",
   "id": "roman-stereo",
   "metadata": {},
   "source": [
    "# Remaking nose graph\n",
    "nose_graph = makeGraph(nose_list, verbose_edges=True)\n",
    "nose_n_occ = sortNodesByNOcc(nose_graph)\n",
    "\n",
    "# Remaking palate graph\n",
    "palate_graph = makeGraph(palate_list, verbose_edges=True)\n",
    "palate_n_occ = sortNodesByNOcc(palate_graph)\n",
    "\n",
    "# Remaking finish graph\n",
    "finish_graph = makeGraph(finish_list, verbose_edges=True)\n",
    "finish_n_occ = sortNodesByNOcc(finish_graph)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "becoming-second",
   "metadata": {},
   "source": [
    "with open(\"graphs/nose.prim.json\", \"w\") as out:\n",
    "    json.dump(nose_graph, out)\n",
    "with open(\"graphs/finish.prim.json\", \"w\") as out:\n",
    "    json.dump(finish_graph, out)\n",
    "with open(\"graphs/palate.prim.json\", \"w\") as out:\n",
    "    json.dump(palate_graph, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aboriginal-mentor",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"graphs/nose.prim.json\") as json_in:\n",
    "    nose_graph = json.load(json_in)\n",
    "with open(\"graphs/palate.prim.json\") as json_in:\n",
    "    palate_graph = json.load(json_in)\n",
    "with open(\"graphs/finish.prim.json\") as json_in:\n",
    "    finish_graph = json.load(json_in)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "requested-graph",
   "metadata": {},
   "source": [
    "cuts = np.arange(10, 160, 10)\n",
    "\n",
    "len_nose = len(nose_list)\n",
    "len_palate = len(palate_list)\n",
    "len_finish = len(finish_list)\n",
    "\n",
    "for n in cuts:\n",
    "    nose_val = getUnrepresentedCount(nose_list, nose_n_occ[:n])\n",
    "    palate_val = getUnrepresentedCount(palate_list, palate_n_occ[:n])\n",
    "    finish_val = getUnrepresentedCount(finish_list, finish_n_occ[:n])\n",
    "    print(f\"N of Words: {n}\")\n",
    "    print(f\"Nose : {nose_val} unrepresented ({100 * nose_val / len_nose}%)\")\n",
    "    print(f\"Palate : {palate_val} unrepresented ({100 * palate_val / len_palate}%)\")\n",
    "    print(f\"Finish : {finish_val} unrepresented ({100 * finish_val / len_finish}%)\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "inclusive-benjamin",
   "metadata": {},
   "source": [
    "N of Words: 10\n",
    "Nose : 920 unrepresented (18.81775414195132%)\n",
    "Palate : 752 unrepresented (15.381468602986295%)\n",
    "Finish : 1628 unrepresented (33.29924319901821%)\n",
    "\n",
    "N of Words: 20\n",
    "Nose : 280 unrepresented (5.727142564941706%)\n",
    "Palate : 196 unrepresented (4.008999795459194%)\n",
    "Finish : 733 unrepresented (14.992841071793823%)\n",
    "\n",
    "N of Words: 30\n",
    "Nose : 128 unrepresented (2.618122315401923%)\n",
    "Palate : 77 unrepresented (1.5749642053589692%)\n",
    "Finish : 457 unrepresented (9.347514829208427%)\n",
    "\n",
    "N of Words: 40\n",
    "Nose : 62 unrepresented (1.2681529965228062%)\n",
    "Palate : 45 unrepresented (0.9204336265084885%)\n",
    "Finish : 310 unrepresented (6.340764982614031%)\n",
    "\n",
    "N of Words: 50\n",
    "Nose : 30 unrepresented (0.6136224176723256%)\n",
    "Palate : 26 unrepresented (0.5318060953160155%)\n",
    "Finish : 212 unrepresented (4.336265084884435%)\n",
    "\n",
    "N of Words: 60\n",
    "Nose : 21 unrepresented (0.42953569237062794%)\n",
    "Palate : 21 unrepresented (0.42953569237062794%)\n",
    "Finish : 164 unrepresented (3.3544692166087136%)\n",
    "\n",
    "N of Words: 70\n",
    "Nose : 15 unrepresented (0.3068112088361628%)\n",
    "Palate : 10 unrepresented (0.2045408058907752%)\n",
    "Finish : 126 unrepresented (2.5772141542237677%)\n",
    "\n",
    "N of Words: 80\n",
    "Nose : 10 unrepresented (0.2045408058907752%)\n",
    "Palate : 6 unrepresented (0.12272448353446512%)\n",
    "Finish : 99 unrepresented (2.0249539783186745%)\n",
    "\n",
    "N of Words: 90\n",
    "Nose : 8 unrepresented (0.16363264471262018%)\n",
    "Palate : 5 unrepresented (0.1022704029453876%)\n",
    "Finish : 74 unrepresented (1.5136019635917366%)\n",
    "\n",
    "N of Words: 100\n",
    "Nose : 7 unrepresented (0.14317856412354266%)\n",
    "Palate : 0 unrepresented (0.0%)\n",
    "Finish : 60 unrepresented (1.2272448353446512%)\n",
    "\n",
    "N of Words: 110\n",
    "Nose : 4 unrepresented (0.08181632235631009%)\n",
    "Palate : 0 unrepresented (0.0%)\n",
    "Finish : 53 unrepresented (1.0840662712211087%)\n",
    "\n",
    "N of Words: 120\n",
    "Nose : 3 unrepresented (0.06136224176723256%)\n",
    "Palate : 0 unrepresented (0.0%)\n",
    "Finish : 48 unrepresented (0.981795868275721%)\n",
    "\n",
    "N of Words: 130\n",
    "Nose : 2 unrepresented (0.040908161178155045%)\n",
    "Palate : 0 unrepresented (0.0%)\n",
    "Finish : 42 unrepresented (0.8590713847412559%)\n",
    "\n",
    "N of Words: 140\n",
    "Nose : 2 unrepresented (0.040908161178155045%)\n",
    "Palate : 0 unrepresented (0.0%)\n",
    "Finish : 36 unrepresented (0.7363469012067908%)\n",
    "\n",
    "N of Words: 150\n",
    "Nose : 2 unrepresented (0.040908161178155045%)\n",
    "Palate : 0 unrepresented (0.0%)\n",
    "Finish : 31 unrepresented (0.6340764982614031%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surgical-nature",
   "metadata": {},
   "source": [
    "Based on a quick look, 100 words for each seems to get a very good coverage of dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sweet-helmet",
   "metadata": {},
   "source": [
    "## Graph Visualisations\n",
    "\n",
    "Found very difficult to find a 'good' grpah visualisation with this many nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ordinary-hungarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "local-natural",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph2NX(g, title):\n",
    "    G = nx.Graph(name=title)\n",
    "    nodes = g[\"nodes\"]\n",
    "    for idx, node in enumerate(nodes):\n",
    "        G.add_node(node[\"name\"], name=node[\"name\"], nocc=node[\"n_occ\"])\n",
    "    \n",
    "    edges = []\n",
    "    for edge in g[\"edges\"]:\n",
    "        edges.append(\n",
    "            (nodes[edge[\"from\"]][\"name\"], nodes[edge[\"to\"]][\"name\"], edge[\"weight\"])\n",
    "        )\n",
    "    G.add_weighted_edges_from(edges)\n",
    "    \n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "gross-austin",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "def graph2PV(g, notebook=False, dims=(1000,700)):\n",
    "    \"\"\"\n",
    "    Function to display graphs in networkx\n",
    "    \"\"\"\n",
    "    \n",
    "    net = Network(width=str(dims[0])+'px',height=str(dims[1])+'px',notebook=notebook)\n",
    "    \n",
    "    g_nodes = g[\"nodes\"]\n",
    "    g_edges = g[\"edges\"]\n",
    "    \n",
    "    nodes = np.arange(len(g[\"nodes\"]))\n",
    "    \n",
    "    props = list(zip(*[(node[\"name\"], node[\"n_occ\"]) for node in g[\"nodes\"]]))\n",
    "    names = list(props[0])\n",
    "    n_occ = list(props[1])\n",
    "    \n",
    "    net.add_nodes(nodes, value=n_occ,\n",
    "                         title=names)\n",
    "    \n",
    "    #net.add_edges([(edge[\"from\"], edge[\"to\"], edge[\"weight\"]) for edge in g_edges])\n",
    "    net.edges = [{'width':edge[\"weight\"],'from':edge[\"from\"],'to':edge[\"to\"]} for edge in g_edges]\n",
    "    \n",
    "    net.show_buttons(filter_=[\"nodes\", \"edges\", \"physics\"])\n",
    "    \n",
    "    net.set_options('{\"layout\":true}')\n",
    "    \n",
    "    return net\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "honest-export",
   "metadata": {},
   "outputs": [],
   "source": [
    "nose_vis = graph2PV(nose_graph)\n",
    "nose_vis.show(\"nose_vis.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "junior-companion",
   "metadata": {},
   "outputs": [],
   "source": [
    "palate_vis = graph2PV(palate_graph)\n",
    "palate_vis.show(\"palate_vis.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "second-flour",
   "metadata": {},
   "outputs": [],
   "source": [
    "finish_vis = graph2PV(finish_graph)\n",
    "finish_vis.show(\"finish_vis.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "christian-chick",
   "metadata": {},
   "outputs": [],
   "source": [
    "nose_nx = graph2NX(nose_graph, \"Nose\")\n",
    "palate_nx = graph2NX(palate_graph, \"Palate\")\n",
    "finish_nx = graph2NX(finish_graph, \"Finish\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-uncle",
   "metadata": {},
   "source": [
    "# Testing Eigencentrality RAKE\n",
    "Testing what eigencentrality RAKE produces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "continuous-rhythm",
   "metadata": {},
   "outputs": [],
   "source": [
    "from whiskynlp.GraphKeywordExtraction import GraphKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "discrete-workplace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Corpus\n",
      "Building Graph\n",
      "Ranking Nodes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('long', 0.3315870919125884),\n",
       " ('spice', 0.3107726573888594),\n",
       " ('oak', 0.2976290779752006),\n",
       " ('sweet', 0.27160653062623674),\n",
       " ('fruit', 0.2688196361323793),\n",
       " ('smoke', 0.23526105087172744),\n",
       " ('dry', 0.2247697418298472),\n",
       " ('pepper', 0.190878219669847),\n",
       " ('chocolate', 0.1631098714699105),\n",
       " ('malt', 0.1461320618887879),\n",
       " ('vanilla', 0.14155751532720273),\n",
       " ('spicy', 0.1208973475380097),\n",
       " ('honey', 0.11884194886265252),\n",
       " ('length', 0.10956742803932186),\n",
       " ('orange', 0.10500881137730003),\n",
       " ('warm', 0.09997421144076435),\n",
       " ('nut', 0.09666299139694369),\n",
       " ('sugar', 0.09556504325312482),\n",
       " ('peat', 0.09460690635633463),\n",
       " ('cinnamon', 0.09201346296830785),\n",
       " ('dark', 0.09106126239482776),\n",
       " ('barley', 0.09094528628362741),\n",
       " ('toast', 0.09084237055062981),\n",
       " ('black', 0.08773798720701322),\n",
       " ('rich', 0.08753694505120678),\n",
       " ('cream', 0.08654084327040498),\n",
       " ('butter', 0.08622728758188528),\n",
       " ('last', 0.08621590632135873),\n",
       " ('salt', 0.08586422355151505),\n",
       " ('apple', 0.08263846507215322),\n",
       " ('caramel', 0.08054328962964491),\n",
       " ('peel', 0.08045595158526588),\n",
       " ('oil', 0.07955583546277463),\n",
       " ('slight', 0.07948936187382599),\n",
       " ('ginger', 0.07782696542087196),\n",
       " ('toffee', 0.07654806246967814),\n",
       " ('medium', 0.07428581139738533),\n",
       " ('fresh', 0.07169752996050108),\n",
       " ('little', 0.07126900870177955),\n",
       " ('citrus', 0.07039522016046691),\n",
       " ('tail', 0.06219086081374428),\n",
       " ('wood', 0.06153080036350844),\n",
       " ('bit', 0.06070772061178129),\n",
       " ('soft', 0.05813669382228743),\n",
       " ('quite', 0.056250077530099085),\n",
       " ('herb', 0.05562890939838273),\n",
       " ('char', 0.05425453088184068),\n",
       " ('red', 0.05391763514876599),\n",
       " ('sherry', 0.05245126017001719),\n",
       " ('balance', 0.05204697895041331),\n",
       " ('white', 0.05084763097103649),\n",
       " ('lemon', 0.04987404186801325),\n",
       " ('brown', 0.04945468716875159),\n",
       " ('coffee', 0.04636284564112237),\n",
       " ('milk', 0.04154917507332875),\n",
       " ('sea', 0.04117818603531872),\n",
       " ('gentle', 0.04008856433804741),\n",
       " ('clove', 0.03997619701208812),\n",
       " ('floral', 0.03873944462435549),\n",
       " ('cocoa', 0.03799018653120917),\n",
       " ('earthy', 0.037315265809820065),\n",
       " ('zest', 0.036681475977042396),\n",
       " ('light', 0.03607253638861198),\n",
       " ('subtle', 0.03589849362878593),\n",
       " ('raisin', 0.03578584341184525),\n",
       " ('develop', 0.03548040335795517),\n",
       " ('berry', 0.03501374451809253),\n",
       " ('continue', 0.03431182645732404),\n",
       " ('almond', 0.034090906270131456),\n",
       " ('baking', 0.03406075720382931),\n",
       " ('jam', 0.03339427247483213),\n",
       " ('still', 0.03321778630346554),\n",
       " ('grass', 0.03309637603175885),\n",
       " ('end', 0.03301272521088421),\n",
       " ('walnut', 0.030305289645214468),\n",
       " ('biscuit', 0.02954980450780114),\n",
       " ('green', 0.028358662598566963),\n",
       " ('mint', 0.027544921802721858),\n",
       " ('orchard', 0.027530249740183817),\n",
       " ('apricot', 0.026923260189966464),\n",
       " ('syrup', 0.026755001285343884),\n",
       " ('cake', 0.026470377762312647),\n",
       " ('tobacco', 0.025910089408760786),\n",
       " ('tangy', 0.02570499437850737),\n",
       " ('appear', 0.025528139262590555),\n",
       " ('pear', 0.025458968974178625),\n",
       " ('heat', 0.02494416012881823),\n",
       " ('remain', 0.0247268323029122),\n",
       " ('grape', 0.02455485807581672),\n",
       " ('plum', 0.02388846626684084),\n",
       " ('juicy', 0.023530614141046496),\n",
       " ('though', 0.02351667294200388),\n",
       " ('return', 0.023236140836663175),\n",
       " ('marmalade', 0.023142548920262837),\n",
       " ('bonfire', 0.02274982369121402),\n",
       " ('leather', 0.022166099060727616),\n",
       " ('pinch', 0.022121855856272445),\n",
       " ('candy', 0.021889183134368204),\n",
       " ('ice', 0.020904261799005813),\n",
       " ('stick', 0.02089405045866509)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KE = GraphKE()\n",
    "KE.keywordExtract(df, \"Finish\", 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
