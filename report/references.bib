@article{Ranjan2016,
abstract = {The field of natural language processing (aka NLP) is an intersection of the study of linguistics, computation and statistics. The primary goal of NLP is automated understanding of the semi-structured language that humans use. This study stems application in diverse fields like semantic analysis, summarization, text classification and the like. The domain natural language processing is a fledgling domain with no concrete indication of when it will mature. Compared to well established domains like "Study of Algorithms", NLP is yet in its emerging period and hence there's dearth of a concise piece of literature that elaborates on the phases of NLP and lists different techniques that can be adapted. NLP borrows heavily from foundational subjects of study like statistics, probability theory and theory of computation. In this paper, we describe three phases of natural language processing namely, language modelling, parts-of-speech tagging and parsing, outlining the approaches used that can be used.},
author = {Ranjan, Nihar and Mundada, Kaushal and Phaltane, Kunal and Ahmad, Saim},
doi = {10.5120/ijca2016907355},
file = {:C$\backslash$:/Users/rober/Google Drive/Notes and Books/Mendeley/Ranjan et al/International Journal of Computer Applications/Ranjan et al. - 2016 - A Survey on Techniques in NLP.pdf:pdf},
journal = {International Journal of Computer Applications},
mendeley-groups = {NLP},
number = {8},
pages = {6--9},
title = {{A Survey on Techniques in NLP}},
volume = {134},
year = {2016}
}
@book{Jacques2003,
abstract = {Lignocellulosic materials have a very complex configuration that contains a variety of active sites capable, in some cases, of adsorbing contaminants from water. Agave bagasse is a sub-product from the alcohol industry that has been very little studied, but that could have the potential to remove a variety of contaminants from aqueous solutions.Raw and modified Agave salmiana bagasse were characterized, before and after they were tested to remove metal cations, by acid-base titrations, elemental analysis and ATR-FTIR. HCl, HNO 3, NaOH, tartaric, citric and oxalic acids were used to modify bagasse to determine if its concentration of active groups could be improved. These materials were then tested for the removal of Cd(II), Pb(II) and Zn(II) ions from water at pH 5, and desorption studies were performed at pH 2 and 4 at 25??C.The characterization techniques mainly identified carboxyl, hydroxyl, sulfur and nitrogen containing groups in bagasse. It was clear that mainly the carboxylic groups were responsible for metal uptake. Raw bagasse has an adsorption capacity of about 8, 14 and 36mgg -1 for zinc, cadmium and lead, respectively, and this was improved about 27-62{\%} upon modification with HNO 3 and NaOH. Treatments with citric, oxalic and tartaric acid did not have a significant effect in adsorption capacity.Raw agave bagasse has a very acceptable adsorption capacity of metal cations and it can approximately be regenerated in a 45{\%}, since the biosorption mechanism involves ion exchange and complexation. ?? 2012 Elsevier B.V.},
author = {Jacques, K.A. and Lyons, T.P. and Kelsall, D.R.},
booktitle = {In: Jacques KA, Lyons TP, Kelsall DR (eds) The alcohol textbook},
edition = {4},
file = {:C$\backslash$:/Users/rober/Google Drive/Notes and Books/Mendeley/Jacques, Lyons, Kelsall/In Jacques KA, Lyons TP, Kelsall DR (eds) The alcohol textbook/Jacques, Lyons, Kelsall - 2003 - The Alcohol Textbook 4th edition.pdf:pdf},
isbn = {1-897676-13-1},
pages = {223--245},
publisher = {Nottingham University Press},
title = {{The Alcohol Textbook 4th edition}},
year = {2003}
}
@article{Pyke1965,
author = {Pyke, Magnus},
file = {:C$\backslash$:/Users/rober/Google Drive/Notes and Books/Mendeley/Pyke/The Distillers Company Ltd., Glenochil Research Station, Menstrie, Clackmannanshirc, Scotland)/Pyke - 1965 - THE MANUFACTURE OF SCOTCH GRAIN WHISKY.pdf:pdf},
journal = {The Distillers Company Ltd., Glenochil Research Station, Menstrie, Clackmannanshirc, Scotland)},
pages = {209--218},
title = {{THE MANUFACTURE OF SCOTCH GRAIN WHISKY}},
volume = {71},
year = {1965}
}
@article{legislation.gov.uk_2009,
title={The Scotch Whisky Regulations 2009},
url={https://www.legislation.gov.uk/uksi/2009/2890/contents/made},
journal={Legislation.gov.uk},
publisher={Queen's Printer of Acts of Parliament},
year={2009}}
@article{Bathgate2019,
abstract = {Over the last 50 years there has been considerable analytical research on the malt parameters which govern the flavour and aroma, i.e. the ‘character', of Scotch malt whisky. This has led to a standard format, the Flavour Wheel, to describe the attributes of any malt spirit and to relate them to a common group of malt parameters. What has not been well documented in the same period are the changes in malt processing technology which have led to a gradual but significant change in the concentrations of reference compounds used in the Flavour Wheel relating to sulphury, nutty/burnt/smoky, peaty and fruity/estery characters. This review covers the most significant of these changes, which have become common practice across the industry, and specifically demonstrates how different malting barley varieties, malt kilning and peating, wort recovery, yeast management, and wash still heating have all contributed to the loss of some styles of malt whisky. {\textcopyright} 2019 The Institute of Brewing {\&} Distilling.},
author = {Bathgate, George N.},
doi = {10.1002/jib.556},
file = {:C$\backslash$:/Users/rober/Google Drive/Notes and Books/Mendeley/Bathgate/Unknown/Bathgate - 2019 - The influence of malt and wort processing on spirit character the lost styles of Scotch malt whisky.pdf:pdf},
issn = {20500416},
journal = {Journal of the Institute of Brewing},
keywords = {distilling,flavour,furfural,kilning,malt,malt whisky,peat,phenols,spirit character,wort clarity},
number = {2},
pages = {200--213},
title = {{The influence of malt and wort processing on spirit character: the lost styles of Scotch malt whisky}},
volume = {125},
year = {2019}
}
@article{Valaer1940,
author = {Valaer, Peter},
file = {:C$\backslash$:/Users/rober/Google Drive/Notes and Books/Mendeley/Valaer/Industrial and Engineering Chemistry/Valaer - 1940 - Scotch Whisky.pdf:pdf},
journal = {Industrial and Engineering Chemistry},
number = {7},
pages = {935--943},
title = {{Scotch Whisky}},
volume = {32},
year = {1940}
}
@article{Smith2017,
abstract = {Background: Although most Scotch whisky is blended from different casks, a firm distinction exists in the minds of consumers and in the marketing of Scotch between single malts and blended whiskies. Consumers are offered cultural, geographical and production reasons to treat Scotch whiskies as falling into the categories of blends and single malts. There are differences in the composition, method of distillation and origin of the two kinds of bottled spirits. But does this category distinction correspond to a perceptual difference detectable by whisky drinkers? Do experts and novices show differences in their perceptual sensitivities to the distinction between blends and single malts? To test the sensory basis of this distinction, we conducted a series of blind tasting experiments in three countries with different levels of familiarity with the blends versus single malts distinction (the UK, the USA and France). In each country, expert and novice participants had to perform a free sorting task on nine whiskies (four blends, four single malts, one single grain, plus one repeat) first by olfaction, then by tasting.},
author = {Smith, Barry C. and Sester, Carole and Ballester, Jordi and Deroy, Ophelia},
doi = {10.1186/s13411-017-0056-x},
file = {:C$\backslash$:/Users/rober/Google Drive/Notes and Books/Mendeley/Smith et al/Unknown/Smith et al. - 2017 - The perceptual categorisation of blended and single malt Scotch whiskies.pdf:pdf},
issn = {2044-7248},
journal = {Flavour},
number = {1},
pages = {1--9},
publisher = {Flavour},
title = {{The perceptual categorisation of blended and single malt Scotch whiskies}},
volume = {6},
year = {2017}
}
@article{Mosedale1998,
author = {Mosedale, J.R and Puech, J.-L},
doi = {10.1016/S0924-2244(98)00024-7},
file = {:C$\backslash$:/Users/rober/Google Drive/Notes and Books/Mendeley/Mosedale, Puech/Trends in Food Science {\&} Technology/Mosedale, Puech - 1998 - Wood maturation of distilled beverages.pdf:pdf},
issn = {09242244},
journal = {Trends in Food Science {\&} Technology},
month = {mar},
number = {3},
pages = {95--101},
title = {{Wood maturation of distilled beverages}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0924224498000247},
volume = {9},
year = {1998}
}
@book{StevenBirdEwanKlein2009,
author = {{Steven Bird, Ewan Klein}, Edward Loper},
file = {:C$\backslash$:/Users/rober/Google Drive/Notes and Books/Mendeley/Steven Bird, Ewan Klein/Unknown/Steven Bird, Ewan Klein - 2009 - Natural Language Processing with Python.pdf:pdf},
isbn = {978-0-596-51649-9},
mendeley-groups = {NLP},
publisher = {O'Reilly Media Inc},
title = {{Natural Language Processing with Python}},
year = {2009}
}
@article{Cambria2014,
abstract = {Natural language processing (NLP) is a theory-motivated range of computational techniques for the automatic analysis and representation of human language. NLP research has evolved from the era of punch cards and batch processing (in which the analysis of a sentence could take up to 7 minutes) to the era of Google and the likes of it (in which millions of webpages can be processed in less than a second). This review paper draws on recent developments in NLP research to look at the past, present, and future of NLP technology in a new light. Borrowing the paradigm of 'jumping curves' from the field of business management and marketing prediction, this survey article reinterprets the evolution of NLP research as the intersection of three overlapping curves-namely Syntactics, Semantics, and Pragmatics Curves- which will eventually lead NLP research to evolve into natural language understanding.},
author = {Cambria, Erik and White, Bebo},
doi = {10.1109/MCI.2014.2307227},
file = {:C$\backslash$:/Users/rober/Google Drive/Notes and Books/Mendeley/Cambria, White/IEEE Computational Intelligence Magazine/Cambria, White - 2014 - Jumping NLP curves A review of natural language processing research.pdf:pdf},
issn = {1556-603X},
journal = {IEEE Computational Intelligence Magazine},
mendeley-groups = {NLP},
month = {may},
number = {2},
pages = {48--57},
publisher = {IEEE},
title = {{Jumping NLP Curves: A Review of Natural Language Processing Research [Review Article]}},
url = {http://ieeexplore.ieee.org/document/6786458/},
volume = {9},
year = {2014}
}
@article{Zhang2010,
abstract = {The bag-of-words model is one of the most popular representation methods for object categorization. The key idea is to quantize each extracted key point into one of visual words, and then represent each image by a histogram of the visual words. For this purpose, a clustering algorithm (e.g., K-means), is generally used for generating the visual words. Although a number of studies have shown encouraging results of the bag-of-words representation for object categorization, theoretical studies on properties of the bag-of-words model is almost untouched, possibly due to the difficulty introduced by using a heuristic clustering process. In this paper, we present a statistical framework which generalizes the bag-of-words representation. In this framework, the visual words are generated by a statistical process rather than using a clustering algorithm, while the empirical performance is competitive to clustering-based method. A theoretical analysis based on statistical consistency is presented for the proposed framework. Moreover, based on the framework we developed two algorithms which do not rely on clustering, while achieving competitive performance in object categorization when compared to clustering-based bag-ofwords representations. {\textcopyright} Springer-Verlag 2010.},
author = {Zhang, Yin and Jin, Rong and Zhou, Zhi Hua},
doi = {10.1007/s13042-010-0001-0},
file = {:C$\backslash$:/Users/rober/Google Drive/Notes and Books/Mendeley/Zhang, Jin, Zhou/International Journal of Machine Learning and Cybernetics/Zhang, Jin, Zhou - 2010 - Understanding bag-of-words model A statistical framework.pdf:pdf},
issn = {18688071},
journal = {International Journal of Machine Learning and Cybernetics},
keywords = {Bag of words model,Object recognition,Rademacher complexity},
mendeley-groups = {NLP},
number = {1-4},
pages = {43--52},
title = {{Understanding bag-of-words model: A statistical framework}},
volume = {1},
year = {2010}
}
@article{Plisson2004,
abstract = {Lemmatization is the process of finding the normalized form of a word. It is the same as looking for a transformation to apply on a word to get its normalized form. The approach presented in this paper focuses on word endings: what word suffix should be removed and/or added to get the normalized form. This paper compares the results of two word lemmatization algorithms, one based on if-then rules and the other based on ripple down rules induction algorithms. It presents the problem of lemmatization of words from Slovene free text and explains why the Ripple Down Rules (RDR) approach is very well suited for the task. When learning from a corpus of lemmatized Slovene words the RDR approach results in easy to understand rules of improved classification accuracy compared to the results of rule learning achieved in previous work},
author = {Plisson, Jo{\"{e}}l and Lavrac, Nada and Mladeni{\'{c}}, Dr. Dunja},
file = {:C$\backslash$:/Users/rober/Google Drive/Notes and Books/Mendeley/Plisson, Lavrac, Mladeni{\'{c}}/Proceedings of the 7th International Multiconference Information Society (IS'04)/Plisson, Lavrac, Mladeni{\'{c}} - 2004 - A rule based approach to word lemmatization.pdf:pdf},
journal = {Proceedings of the 7th International Multiconference Information Society (IS'04)},
keywords = {Information Retrieval {\&} Textual Information Access,Natural Language Processing},
mendeley-groups = {Whisky Classification},
number = {November},
pages = {83--86},
title = {{A rule based approach to word lemmatization}},
url = {http://eprints.pascal-network.org/archive/00000715/},
year = {2004}
}
@article{Porter1980,
author = {Porter, M.F.},
doi = {10.1108/eb046814},
file = {:C$\backslash$:/Users/rober/Google Drive/Notes and Books/Mendeley/Porter/Program/Porter - 1980 - An algorithm for suffix stripping.pdf:pdf},
issn = {0033-0337},
journal = {Program},
month = {mar},
number = {3},
pages = {130--137},
title = {{An algorithm for suffix stripping}},
url = {https://www.emerald.com/insight/content/doi/10.1108/eb046814/full/html},
volume = {14},
year = {1980}
}
@article{Jayakodi2016,
abstract = {Assessment usually plays an indispensable role in the education and it is the prime indicator of student learning achievement. Exam questions are the main form of assessment used in learning. Setting appropriate exam questions to achieve the desired outcome of the course is a challenging work for the examiner. Therefore this research is mainly focused to categorize the exam questions automatically into its learning levels using Bloom's taxonomy. Natural Language Processing (NLP) techniques such as tokenization, stop word removal, lemmatization and tagging were used prior to generating the rule set to be used for this classification. WordNet similarity algorithms with NLTK and cosine similarity algorithm were developed to generate a unique set of rules to identify the question category and the weight for each exam question according to Bloom's taxonomy. These derived rules make it easy to analyze the exam questions. Evaluators can redesign their exam papers based on the outcome of this classification process. A sample of examination questions of the Department of Computing and Information Systems, Wayamba University, Sri Lanka was used for the evaluation; weight assignment was done based on the total value generated from both WordNet algorithm and the cosine algorithm. Identified question categories were confirmed by a domain expert. The generated rule set indicated over 70{\%} accuracy.},
author = {Jayakodi, K. and Bandara, M. and Perera, I. and Meedeniya, D.},
doi = {10.3991/ijet.v11i04.5654},
file = {:C$\backslash$:/Users/rober/Google Drive/Notes and Books/Mendeley/Jayakodi et al/Unknown/Jayakodi et al. - 2016 - WordNet and Cosine Similarity based Classifier of Exam Questions using Bloom ' s Taxonomy.pdf:pdf},
issn = {18630383},
journal = {International Journal of Emerging Technologies in Learning},
keywords = {Bloom's taxonomy,Cosine similarity,Learning Analytics,Natural Language Processing,Question classification,Teaching and Supporting Learning},
number = {4},
pages = {142--149},
title = {{WordNet and cosine similarity based classifier of exam questions using bloom's taxonomy}},
volume = {11},
year = {2016}
}
@misc{princetonuniversity_2010,
title={What is WordNet?},
url={https://wordnet.princeton.edu/},
journal={Princeton University},
publisher={The Trustees of Princeton University},
year={2010}
}
@article{Ramos2003,
abstract = {In this paper, we examine the results of applying Term Frequency Inverse Document Frequency (TF-IDF) to determine what words in a corpus of documents might be more favorable to use in a query. As the term implies, TF-IDF calculates values for each word in a document through an inverse proportion of the frequency of the word in a particular document to the percentage of documents the word appears in. Words with high TF-IDF numbers imply a strong relationship with the document they appear in, suggesting that if that word were to appear in a query, the document could be of interest to the user. We provide evidence that this simple algorithm efficiently categorizes relevant words that can enhance query retrieval.},
author = {Ramos, Juan},
file = {:C$\backslash$:/Users/rober/Google Drive/Notes and Books/Mendeley/Ramos/Proceedings of the first instructional conference on machine learning/Ramos - 2003 - Using TF-IDF to Determine Word Relevance in Document Queries.pdf:pdf},
journal = {Proceedings of the first instructional conference on machine learning},
mendeley-groups = {NLP},
number = {1},
pages = {29--48},
title = {{Using TF-IDF to Determine Word Relevance in Document Queries}},
volume = {242},
year = {2003}
}

@article{Barupal2011,
abstract = {Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.sourceforge.net.},
author = {Fabian, Pedregosam and Varoquaux, Gael and Gramfort, Alexandre and Vincent, Michel and Thririon, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David and Brucher, Matthieu and Perrot, Mattieu and Duchesnay, Edouard},
file = {:C$\backslash$:/Users/rober/Google Drive/Notes and Books/Mendeley/Fabian et al/Journal of Machine Learning Research/Fabian et al. - 2011 - Scikit-learn Machine Learning in Python.pdf:pdf},
journal = {Journal of Machine Learning Research},
number = {85},
pages = {2825--2830},
title = {{Scikit-learn: Machine Learning in Python}},
volume = {12},
year = {2011}
}
@misc{muhammad,
title={Graph Theory: Definitions and Examples},
url={http://personal.kent.edu/~rmuhamma/GraphTheory/MyGraphTheory/defEx.htm}, 
journal={Graph Theory},
author={Muhammad, Rashid Bin}
}
@article{Rose2010,
abstract = {RAKE algorithm},
author = {Rose, Stuart and Engel, Dave and Cramer, Nick and Cowley, Wendy},
file = {:C$\backslash$:/Users/rober/Google Drive/Notes and Books/Mendeley/Rose et al/Text Mining Applications and Theory/Rose et al. - 2010 - Automatic keyword extraction.pdf:pdf},
isbn = {9780470749821},
issn = {0926-9630},
journal = {Text Mining: Applications and Theory},
keywords = {a sequence of one,compact representation of a,condensed form the essential,content of a document,document,easy to,ideally,information retrieval,ir,keywords are widely used,keywords represent in,or more words,provide a,s content,systems as they are,to define queries within,which we define as},
mendeley-groups = {Graph Based Keyword Extraction},
pages = {1----277},
pmid = {25160349},
title = {{Automatic keyword extraction}},
year = {2010}
}
@article{Page1998,
abstract = {The importance of a Web page is an inherently subjective matter, which depends on the readers interests, knowledge and attitudes. But there is still much that can be said objectively about the relative importance of Web pages. This paper describes PageRank, a method for rating Web pages objectively and mechanically, effectively measuring the human interest and attention devoted to them. We compare PageRank to an idealized random Web surfer. We show how to efficiently compute PageRank for large numbers of pages. And, we show how to apply PageRank to search and to user navigation},
author = {Page, Lawrence and Brin, Sergey and Motwani, Rajeev and Winograd, Terry},
file = {:C$\backslash$:/Users/rober/Google Drive/Notes and Books/Mendeley/Page et al/Proceedings - 2012 IEEE International Symposium on Workload Characterization, IISWC 2012/Page et al. - 1998 - The PageRank Citation Ranking Bringing Order to the Web.pdf:pdf},
journal = {Proceedings - 2012 IEEE International Symposium on Workload Characterization, IISWC 2012},
title = {{The PageRank Citation Ranking: Bringing Order to the Web}},
year = {1998}
}
@article{Mihalcea2004,
abstract = {In this paper, we introduce TextRank – a graph-based ranking model for text processing, and show how this model can be successfully used in natural language applications. In particular, we propose two innova- tive unsupervised methods for keyword and sentence extraction, and show that the results obtained com- pare favorably with previously published results on established benchmarks.},
author = {Mihalcea, Rada and Tarau, Paul},
doi = {10.1109/ICECTA48151.2019.8959702},
file = {:C$\backslash$:/Users/rober/Google Drive/Notes and Books/Mendeley/Mihalcea, Tarau/Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing/Mihalcea, Tarau - 2004 - TextRank Bringing Order into Texts.pdf:pdf},
isbn = {9781728155326},
journal = {Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing},
keywords = {Blowfish algorithm,computer security,data communication,network security},
title = {{TextRank: Bringing Order into Texts}},
year = {2004}
}

@article{Beliga2015,
author = {Beliga, Slobodan and Mestrovic, Ana and Martincic-Ipsic, Sanda},
file = {:C$\backslash$:/Users/rober/Google Drive/Notes and Books/Mendeley/Beliga, Mestrovic, Martincic-Ipsic/Journal of Information and Organizational Sciences/Beliga, Mestrovic, Martincic-Ipsic - 2015 - An Overview of Graph-Based Keyword Extraction Methods and Approache.pdf:pdf},
journal = {Journal of Information and Organizational Sciences},
mendeley-groups = {Graph Based Keyword Extraction},
number = {1},
title = {{An Overview of Graph-Based Keyword Extraction Methods and Approaches}},
url = {https://hrcak.srce.hr/140857},
volume = {39},
year = {2015}
}
@article{Bonacich2007,
author = {Bonacich, Phillip},
doi = {10.1016/j.socnet.2007.04.002},
file = {:C$\backslash$:/Users/rober/Google Drive/Notes and Books/Mendeley/Unknown/Unknown/Unknown - Unknown - doi{\_}10.1016{\_}j.socnet.2007.04.002 {\_} Elsevier Enhanced Reader.pdf.pdf:pdf},
issn = {03788733},
journal = {Social Networks},
month = {oct},
number = {4},
pages = {555--564},
title = {{Some unique properties of eigenvector centrality}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0378873307000342},
volume = {29},
year = {2007}
}
@article{Newman2010,
abstract = {In much of economic theory it is assumed that economic agents interact, directly or indirectly, with all others, or at least that they have the opportunity to do so in order to achieve a desired outcome for themselves. In reality, as common sense tells us, things are quite different. Traders in a market have preferred trading partners, perhaps because of an established history of trust, or simply for convenience. Buyers and sellers have preferred suppliers and customers. Consumers have preferred brands and outlets. And most individuals limit their interactions, economic or otherwise, to a select circle of partners or acquaintances. In many cases partners are chosen not on economic grounds but for social reasons: individuals tend overwhelmingly to deal with others who revolve in the same circles as they do, socially, intellectually or culturally.},
author = {Newman, M. E. J.},
doi = {10.1093/acprof:oso/9780199206650.003.0006},
file = {:C$\backslash$:/Users/rober/Google Drive/Notes and Books/Mendeley/Newman/Networks/Newman - 2010 - Mathematics of networks.pdf:pdf},
journal = {Networks},
pages = {109--167},
title = {{Mathematics of networks}},
year = {2010}
}
@misc{McCormick2017,
abstract = {This tutorial covers the skip gram neural network architecture for Word2Vec. My intention with this tutorial was to skip over the usual introductory and abstract insights about Word2Vec, and get into more of the details. Specifically here Iʼm diving into the skip gram neural network model.},
author = {McCormick, Chris},
booktitle = {http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/},
file = {:C$\backslash$:/Users/rober/Google Drive/Notes and Books/Mendeley/McCormick/httpmccormickml.com20160419word2vec-tutorial-the-skip-gram-model/McCormick - 2017 - Word2Vec Tutorial - The Skip-Gram Model.pdf:pdf},
mendeley-groups = {NLP},
pages = {1--39},
title = {{Word2Vec Tutorial - The Skip-Gram Model}},
urldate = {2021-05-27},
year = {2017}
}

@article{Liu2020,
abstract = {Contextual embeddings, such as ELMo and BERT, move beyond global word representations like Word2Vec and achieve ground-breaking performance on a wide range of natural language processing tasks. Contextual embeddings assign each word a representation based on its context, thereby capturing uses of words across varied contexts and encoding knowledge that transfers across languages. In this survey, we review existing contextual embedding models, cross-lingual polyglot pre-training, the application of contextual embeddings in downstream tasks, model compression, and model analyses.},
archivePrefix = {arXiv},
arxivId = {2003.07278},
author = {Liu, Qi and Kusner, Matt J. and Blunsom, Phil},
eprint = {2003.07278},
file = {:C$\backslash$:/Users/rober/Google Drive/Notes and Books/Mendeley/Liu, Kusner, Blunsom/Unknown/Liu, Kusner, Blunsom - 2020 - A Survey on Contextual Embeddings.pdf:pdf},
mendeley-groups = {NLP,NLP/Pretrained Models},
title = {{A Survey on Contextual Embeddings}},
url = {http://arxiv.org/abs/2003.07278},
year = {2020}
}
@inproceedings{Mikolov2013,
abstract = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
archivePrefix = {arXiv},
arxivId = {1301.3781},
author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
booktitle = {1st International Conference on Learning Representations, ICLR 2013 - Workshop Track Proceedings},
eprint = {1301.3781},
file = {:C$\backslash$:/Users/rober/Google Drive/Notes and Books/Mendeley/Mikolov et al/1st International Conference on Learning Representations, ICLR 2013 - Workshop Track Proceedings/Mikolov et al. - 2013 - Efficient estimation of word representations in vector space.pdf:pdf},
mendeley-groups = {NLP},
pages = {1--12},
title = {{Efficient estimation of word representations in vector space}},
year = {2013}
}

@article{Melville2010,
author = {Melville, Prem and Sindhwani, Vikas},
file = {:C\:/Users/Robert/Documents/Mendeley Desktop/Melville, Sindhwani, Heights/Unknown/Melville, Sindhwani, Heights - Unknown - Recommender Systems.pdf:pdf},
isbn = {1581131763},
issn = {0001-0782},
journal = {Encyclopaedia of Machine Learning},
pages = {829--838},
title = {{Encyclopaedia of Machine Learning: Recommender Systems}},
url = {https://link.springer.com/content/pdf/10.1007/978-1-4899-7687-1_964.pdf%0Ahttps://link.springer.com/referenceworkentry/10.1007%2F978-0-387-30164-8_705%0Ahttps://link.springer.com/book/10.1007/978-0-387-30164-8%0A%0Ahttp://vikas.sindhwani.org/recommender.p},
year = {2010}
}
@misc{tf_idf_imp,
title={Keyword Extraction: Keyword Extraction in Python},
url={https://www.analyticsvidhya.com/blog/2020/11/words-that-matter-a-simple-guide-to-keyword-extraction-in-python/},
journal={Analytics Vidhya},
author={Prakash, Prachi},
year={2020},
month={Dec}
}
@misc{jenner_2019,
place={Dunedin},
title={peat},
journal={Otago University Press},
publisher={Otago University Press},
author={Jenner, Lynn},
year={2019}
}

@misc{sharmer_2018,
title={rake-nltk},
url={https://pypi.org/project/rake-nltk/},
journal={PyPI},
author={Sharmer, Vishwas B},
year={2018},
month={Jun}
}
@article{hubbard_2020,
place={Nottingham},
title={Lecture: Best Approximation (2)/Eigenvalues and Eigenvectors (1), 17/03/2020},
journal={MATH3036-1-UNUK-SPR-1920 Scientific Computation and Numerical Analysis},
publisher={University of Nottingham},
author={Hubbard, Matthew},
year={2020},
month={Mar}
}
@ARTICLE{2020NumPy,
author  = {Harris, Charles R. and Millman, K. Jarrod and
        van der Walt, Stéfan J and Gommers, Ralf and
        Virtanen, Pauli and Cournapeau, David and
        Wieser, Eric and Taylor, Julian and Berg, Sebastian and
        Smith, Nathaniel J. and Kern, Robert and Picus, Matti and
        Hoyer, Stephan and van Kerkwijk, Marten H. and
        Brett, Matthew and Haldane, Allan and
        Fernández del Río, Jaime and Wiebe, Mark and
        Peterson, Pearu and Gérard-Marchant, Pierre and
        Sheppard, Kevin and Reddy, Tyler and Weckesser, Warren and
        Abbasi, Hameer and Gohlke, Christoph and
        Oliphant, Travis E.},
title   = {Array programming with {NumPy}},
journal = {Nature},
year    = {2020},
volume  = {585},
pages   = {357–362},
doi     = {10.1038/s41586-020-2649-2}
}
@misc{mom_ba,
title={Blair Athol 12 Year Old - Flora and Fauna},
url={https://www.masterofmalt.com/whiskies/blair-athol-12-year-old-whisky/},
journal={Master of Malt}
}
@misc{Herlocker2000,
address = {Mineapolis},
author = {Herlocker, Jonathan and Konstan, Joseph and Reidl, John},
file = {:C$\backslash$:/Users/rober/Google Drive/Notes and Books/Mendeley/Herlocker, Konstan, Reidl/Unknown/Herlocker, Konstan, Reidl - 2000 - Explaining Collaborative Filtering Recommendations.pdf:pdf},
publisher = {Grouplens},
title = {{Explaining Collaborative Filtering Recommendations}},
url = {http://www.grouplens.org},
year = {2000}
}
@article{Mooney2000,
abstract = {Recommender systems improve access to relevant products and information by making personalized suggestions based on previous examples of a user's likes and dislikes. Most existing recommender systems use collaborative filtering methods that base recommendations on other user's preferences. By contrast content-based methods use information about an item itself to make suggestions. This approach has the advantage of being able to recommend previously unrated items to users with unique interests and to provide explanations for its recommendations. We describe a content-based book recommending system that utilizes information extraction and a machine-learning algorithm for text categorization. Initial experimental results demonstrate that this approach can produce accurate recommendations.},
archivePrefix = {arXiv},
arxivId = {cs/9902011},
author = {Mooney, Raymond J. and Roy, Loriene},
doi = {10.1145/336597.336662},
eprint = {9902011},
file = {:C$\backslash$:/Users/rober/Google Drive/Notes and Books/Mendeley/Mooney, Roy/Proceedings of the ACM International Conference on Digital Libraries/Mooney, Roy - 2000 - Content-based book recommending using learning for text categorization.pdf:pdf},
journal = {Proceedings of the ACM International Conference on Digital Libraries},
keywords = {and personalized automated,assisting readers by pro-,be able to build,informed,on this tradition of,recommendations for their patrons,viding cost-effective},
mendeley-groups = {Whisky Classification},
pages = {195--204},
primaryClass = {cs},
title = {{Content-based book recommending using learning for text categorization}},
year = {2000}
}

@article{Omidzohoor,
author = {Omid-zohoor, Alex and Eghtesadi, Ashkan},
file = {:C$\backslash$:/Users/rober/Google Drive/Notes and Books/Mendeley/Omid-zohoor, Eghtesadi/Unknown/Omid-zohoor, Eghtesadi - Unknown - Whisky Recommender.pdf:pdf},
mendeley-groups = {Whisky Classification},
title = {{Whisky Recommender}}
}

@incollection{Wishart2000,
abstract = {Tasting notes in 10 recently published books on malt whisky were coded and analysed for 84 single malt whiskies. Over 400 aromatic and taste descriptors were identified and grouped into 12 sensory features, from which a synonymy of the whisky literature was developed. The 84 malt whiskies were then clustered into 10 groups using the FocalPoint clustering method in ClustanGraphics. An industry survey to validate the classification is described, and applications in product design, brand management and marketing are discussed. A tutored tasting of selected single malt whiskies follows the technical presentation.},
author = {Wishart, David},
doi = {10.1007/978-3-642-59789-3_14},
file = {:C$\backslash$:/Users/rober/Google Drive/Notes and Books/Mendeley/Wishart/Unknown/Wishart - 2000 - Classification of Single Malt Whiskies.pdf:pdf},
mendeley-groups = {Whisky Classification},
pages = {89--94},
title = {{Classification of Single Malt Whiskies}},
url = {http://link.springer.com/10.1007/978-3-642-59789-3{\_}14},
year = {2000}
}
@article{Wishart2009,
author = {Wishart, David},
doi = {10.1111/j.1740-9713.2009.00337.x},
file = {:C$\backslash$:/Users/rober/Google Drive/Notes and Books/Mendeley/Wishart/Significance/Wishart - 2009 - The flavour of whisky.pdf:pdf},
issn = {17409705},
journal = {Significance},
month = {mar},
number = {1},
pages = {20--26},
title = {{The flavour of whisky}},
url = {http://doi.wiley.com/10.1111/j.1740-9713.2009.00337.x},
volume = {6},
year = {2009}
}


@article{Coldevin2005,
abstract = {BUILDING AN MULTI-AGENT WHISKY RECOMMENDER SYSTEM by Torje Mj{\o}nes Coldevin MAS (Multi-Agent Systems), classifiers and other AI (Artificial Intelligence) techniques are increasingly becoming more common. The capability to handle complex and advanced problems by MAS was explored in this thesis. An MAS duty-free shopping recommender system was built for this purpose. The MAS system was part of a larger system built by the AmbieSense project. In addition, the AmbieSense project had built a prototype that was tested at Oslo Airport (OSL) Gardermoen. As a test case, the duty-free shopping system was set to classify and recommend whiskies. The system incorporated several AI techniques such as agents, ontology, knowledge base and classifiers. The MAS was built using the JADE-LEAP framework, and Prot{\'{e}}g{\'{e}} was used for constructing the knowledge base. Various tests were performed for testing the system. Firstly, the agent communication was monitored using a Sniffer Agent. Secondly, the system's ability to run on mobile devices was tested on a PDA and various mobile phones. Thirdly, the MAS abilities compared to a 'normal' computer program were tested by replacing agents at run-time, using several JADE platforms, and by the experience gathered during development and the use of the developed system. Lastly, the recommendation was cross-validated against Dr. Wishart's whisky classification.},
author = {Coldevin, Torje Mj{\o}nes},
file = {:C$\backslash$:/Users/rober/Google Drive/Notes and Books/Mendeley/Coldevin/Unknown/Coldevin - 2005 - Building an Multi-Agent Whisky Recommender System.pdf:pdf},
number = {February},
title = {{Building an Multi-Agent Whisky Recommender System}},
year = {2005}
}

@article{richardson2007beautiful,
  title={Beautiful soup documentation},
  author={Richardson, Leonard},
  journal={April},
  year={2007}
}
@software{reback2020pandas,
    author       = {The pandas development team},
    title        = {pandas-dev/pandas: Pandas},
    month        = feb,
    year         = 2020,
    publisher    = {Zenodo},
    version      = {latest},
    doi          = {10.5281/zenodo.3509134},
    url          = {https://doi.org/10.5281/zenodo.3509134}
}

@misc{swa,
title={Scotch Whisky Export figures 2019},
url={https://www.scotch-whisky.org.uk/newsroom/scotch-whisky-exports-surge-amidst-backdrop-of-tariff-uncertainty/},
journal={Scotch Whisky Association}
}
@misc{swa2, 
title={Facts \& Figures}, 
url={https://www.scotch-whisky.org.uk/insights/facts-figures/}, 
journal={Scotch Whisky Association}
}
@misc{n_distilleries,
title={How many whisky distilleries are in Scotland?},
url={https://whiskytastingcompany.com/blogs/news/how-many-whisky-distilleries-are-in-scotland},
journal={Whisky Tasting Co},
year={2020},
month={Oct}
}
@misc{powell_2021, title={The beginner's guide to scotch whisky}, url={https://foodism.co.uk/guides/scotch-whisky-regions-guide/}, journal={Foodism}, author={Powell, Tom}, year={2021}, month={Jan}
}
